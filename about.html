<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ABOUT</title>
     <!-- the website icon -->
     <link rel="icon" type="image/png" href="./imgs/website_icon.png">
    <link
    rel="stylesheet"
    href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/4.1.1/animate.min.css"/>
    <link rel="stylesheet" href="./css/base.css"/>
    <link rel="stylesheet" href="./css/tool.css"/>
    <link rel="stylesheet" href="./css/banner.css"/>
    <link rel="stylesheet" href="./css/about.css"/>

</head>
<body>
    <!-- banner -->
     <header class="banner animate__animated animate__slideInDown">
        <h2 class="gangalin-font">ABOUT</h2>
     </header>

    <!-- aside bar -->
    <aside class="aside more-sugar-font">
        <ul id="navigator-list">
            <li ><a data-divName="goals" class="active" href="#goals" >Website Overview</a></li>
            <li ><a data-divName="technology" href="#technology" >Technology Stack</a></li>
            <li ><a data-divName="database" href="#database" >Database Design</a></li>
            <li ><a data-divName="functionality" href="#functionality" >Core Functionalities</a></li>
            <li ><a data-divName="experience" href="#experience" >User Experience</a></li>
            <li ><a data-divName="credits" href="#credits" >Statement of Credits</a></li>
        </ul>
    </aside>

     <!-- content part -->
     <section class="content">
        <div class="goals" id="goals">
            <h2>Website Overview</h2>
            <p>This website is a bioinformatics platform designed to streamline protein sequence retrieval and analysis, offering an integrated workflow for researchers to obtain sequences, perform computational analyses, and manage past results efficiently. By leveraging PHP, Python, HTML, CSS, JavaScript, and MySQL, the system ensures a seamless user experience with real-time data processing, interactive visualizations, and structured database storage.</p>
            <p>Users can retrieve protein sequences from NCBI, perform multiple sequence alignment, analyze conservation levels, identify functional motifs, and generate phylogenetic trees. The backend automates data retrieval and processing, while the frontend dynamically updates results using fetch-based interactions, eliminating the need for page reloads. A floor-based navigation system enhances usability by allowing users to quickly access different sections of the site.</p>
            <p>To improve accessibility, the website supports pre-stored example data, enabling users to explore its features without waiting for live queries to execute. Additionally, the history tracking system ensures that past searches and analyses can be retrieved instantly, optimizing efficiency and reproducibility.</p>
            <p>Through its intuitive design, automated workflows, and efficient data management, the website provides a powerful and user-friendly tool for protein sequence analysis, enhancing productivity for researchers and bioinformatics professionals.</p>
        </div>
        <div class="technology" id="technology">
            <h2>Technology Stack</h2>
            <p>The website design was primarily created using CANVA, with most illustrations sourced from the platform. Additional images were obtained from Pixabay, as detailed in the credits section. The fundamental structure of the web pages was built using HTML, while CSS was employed for styling and layout. Animations for hover and click interactions were primarily designed using CSS keyframes, with some enhancements achieved through JavaScript. Page entry animations were largely sourced from the Animate.css library.</p>
            <p>The website utilizes custom fonts, specifically MoreSugar and Gangal√≠n. The font files were manually uploaded to the fonts folder and imported into tool.css via @font-face. Fonts were applied across the website using class names. The search icon was integrated using a .ttf font file in an iconfont format, referenced in tool.css. To optimize performance, multiple images were merged into a sprite sheet, reducing the number of HTTP requests and improving page load speed. These sprite images were incorporated using class names in tool.css. All images are stored in the imgs folder, while MP4 videos, which were manually recorded and edited with CapCut, are stored in the videos folder. The CSS files are modularized for clarity and efficiency. The base.css file resets default styles and defines global color variables. The tool.css file manages fonts, icons, and sprite configurations. The banner.css file provides shared styling across multiple pages, such as search, history, and analysis. Each page has its own dedicated CSS file for specific styles. The success_failure.css file defines success and error states for the search and history pages, while analysis-detail.css unifies the styles for all three types of analysis result pages.</p>
            <p>JavaScript was implemented to handle front-end interactions and communication with PHP. It plays a crucial role in dynamic UI effects. For instance, the help section of index page and the analysis page allow users to hover over labels to switch styles and update descriptions dynamically. This effect was achieved using the mouseenter DOM event, event bubbling, and class manipulations. The functionality was encapsulated in the contentChange.js file and imported into the relevant pages. The carousel feature on the analysis page was implemented using a combination of CSS transforms and JavaScript. JavaScript is also responsible for validating user input before submitting data to the backend. On the search page, JavaScript ensures that the user provides both a protein name and a species name before submission. If any required field is left blank, an alert is displayed through a click event listener, preventing the submission of incomplete queries.</p>
            <p>JavaScript also enables real-time page updates. During communication with the backend, it modifies the page state to indicate loading and dynamically switches to displaying results once data retrieval is complete. The fetch API was chosen for handling asynchronous requests due to its Promise-based structure, which enhances encapsulation and simplifies JSON processing. Unlike traditional AJAX, fetch provides a more streamlined approach, automatically handling JSON responses without additional parsing. All requests are executed using the POST method, with data formatted uniformly using FormData. This approach ensures consistency in handling different content types, preventing format discrepancies between JSON and application/x-www-form-urlencoded. Even for &lt;input&gt; fields, data is transmitted via fetch rather than traditional form submissions, allowing for real-time updates without page reloads, improved error handling, and enhanced styling flexibility. Error handling is implemented using try...catch, allowing for centralized management of failures. To support seamless interactions, async/await was utilized to manage asynchronous tasks, particularly when verifying uploaded files before proceeding with further analysis. For instance, once a user uploads a file, JavaScript waits for confirmation of the upload's success before sending data to the corresponding PHP script for further processing. Without async/await, the system might prematurely proceed to the next step before receiving the upload response, potentially leading to failures. All JavaScript logic is modularized, with separate JavaScript files assigned to each page. These scripts are stored in the js folder and imported into the HTML files via the &lt;script type="module" src="./js/xx.js"&gt;&lt;/script&gt; tag.</p>
            <p>The backend logic is handled by PHP, which processes data received from JavaScript and interacts with the MySQL database. PHP retrieves user inputs via $_POST and applies escapeshellarg to mitigate the risk of shell injection before passing data to Python scripts. The exec function is employed to execute Python scripts, with outputs captured through print statements. The response is then processed by PHP and formatted as a JSON object before being returned to JavaScript.</p>
            <p>Session management is implemented. Upon a successful file upload or query execution, PHP generates a unique ID, which is stored in a session variable. This allows analysis scripts, such as conservation.php, to directly retrieve user data from the session, eliminating the need for JavaScript to repeatedly transmit the ID. When performing a search, PHP generates a unique identifier for each query and stores the results in the database using PDO. The analysis results are also stored in the database to enable efficient retrieval. When a user enters a tracking ID, PHP first checks whether previous results exist. If a matching entry is found, the system returns the stored file paths instead of performing redundant computations, significantly reducing processing time. Unlike other analyses, motif results are directly sent from Python to JavaScript without PHP reprocessing. Therefore, motif-related SQL insertions are managed through an independent PHP script.</p>
            <p>Python is responsible for executing biological data retrieval, analysis, and file management. Since PHP lacks sufficient permissions for direct file operations, Python handles all file write operations and stores the results in the results directory. The . The retrieval of protein sequences is facilitated through NCBI edirect (BioPython), which fetches sequence data based on user queries. The phylogenetic analysis component relies on IQ-TREE, while conservation analysis and motif scanning are conducted using EMBOSS tools. Python scripts process user inputs, interact with external tools, generate result files, and return structured outputs to PHP. The overall workflow integrates sequence retrieval, phylogenetic reconstruction, conservation analysis, and motif scanning, with the results structured in JSON format for efficient rendering on the frontend.</p>
        </div>
        <div class="database" id="database">
            <h2>Database Design</h2>
            <p>My database consists of four tables, each serving a specific function within the system. The Searching table is responsible for storing sequence search results. It includes a unique ID (which serves as the primary key), the corresponding FASTA file path (./results/seq_xxx/original_seq.fasta), and information regarding how the sequence was obtained‚Äîwhether it was uploaded by the user or retrieved via a search query. Data is inserted into this table either when a user uploads a file or performs a sequence search.</p>
            <p>The remaining three tables correspond to the three types of analysis: Motif, Tree, and Conservation. Each of these tables has an auto-incrementing ID as the primary key, while also incorporating the unique ID from the Searching table as a foreign key to establish a relational link.</p>
            <p>The Motif table stores the list of motifs identified in the sequences, the total number of sequences analyzed, and the number of sequences that contain motifs. Additionally, it includes the file path to the compressed results package containing all motif analysis outputs.</p>
            <p>The Tree table stores the file path to the Newick-formatted tree file, along with the path to the compressed package containing all tree reconstruction results. Since Newick tree files are often used for visualization in external tools such as iTOL, they are separately provided to users for convenient download and further analysis.</p>
            <p>The Conservation table stores the path to the conservation plot, as this visualization needs to be directly displayed on the frontend for users. It also contains the path to the compressed result package. Data in these three analysis tables is inserted when the corresponding analysis is performed.</p>
            <p>On the History Track page, when a user inputs a tracking ID, it corresponds to the unique ID across all four tables. This tracking ID is sent via JavaScript to PHP, where PDO is used to query the Searching table first. If no result is found, the system immediately returns a response indicating that the ID does not exist. However, if a match is found, PHP proceeds to check the three analysis tables. Since a user may have performed only a sequence search without conducting any analysis, there might be cases where data exists only in the Searching table but not in the analysis tables. In such cases, the system informs the user that the query file was found but no analyses were performed. If results are found in any of the three analysis tables, the system displays the user's previous analysis records in a table format, making it easy for users to review their past analyses.</p>
        </div>
        <div class="functionality" id="functionality">
            <h2>Core Functionalities</h2>
            <p>Protein sequence searching begins when the user inputs a protein name and species name. Before sending the data to the backend, JavaScript performs a simple validation check to ensure both fields are filled. Once validated, the data is sent to PHP, which applies input sanitization to prevent injection attacks before passing the request to a Python script. In Python, Biopython's esearch and efetch functions retrieve the taxonomic ID, as user-provided species names might be too broad for direct searches. If a taxonomic ID cannot be found, the system falls back to using the user's raw input. The script first attempts to obtain an ID list using esearch, and if no results are found, it immediately returns an error to PHP. If an ID list is retrieved, efetch is used to obtain the sequences, which are then written into a file stored in a uniquely named directory. The unique ID is returned to PHP, allowing it to store the relevant metadata in the SQL database.</p>
            <p>Conservation plot generation begins when Python receives the unique ID from PHP. The script navigates to the corresponding directory and performs multiple sequence alignment using EMBOSS's Clustal Omega (clustalo). Once the alignment is complete, plotcon is used to generate the conservation plot. Since plotcon prints output directly to the terminal, which interferes with data transmission to PHP, stdbuf -oL -eL is used to control buffered output. After processing, all relevant files‚Äîincluding the original sequences, aligned sequences, and the conservation plot‚Äîare compressed into a ZIP archive, preventing unnecessary terminal output using zip -qr. The file paths are returned to JavaScript, allowing users to download the results via an &lt;a&gt; tag, while the image path is used for immediate visualization on the web page.</p>
            <p>Motif searching is performed by Python, which first retrieves the unique ID from PHP and navigates to the corresponding directory. The script then extracts each sequence from the original FASTA file and saves them as individual FASTA files. This step is necessary as EMBOSS's patmatmotifs processes each sequence separately. To prevent terminal output interference, stdbuf -oL -eL is used during execution. The motif search results are saved, and the script loops through the generated motif files to count the number of sequences containing motifs and extract motif names. This information is sent directly to JavaScript, where it is displayed dynamically on the results page.</p>
            <p>Tree reconstruction follows a process similar to conservation plot generation, starting with sequence alignment via Clustal Omega. The aligned sequence headers are modified to include both the protein name and species name, ensuring that each node in the final phylogenetic tree is labeled with readable identifiers instead of accession numbers. The system then calls IQ-TREE, a command-line tool for phylogenetic reconstruction. Once the tree file is generated, its file path is returned separately to JavaScript, along with a compressed archive containing all results. Users can download the Newick tree file and upload it to iTOL (Interactive Tree of Life) for visualization and further analysis.</p>
            <p>Example data is pre-stored in the SQL database, allowing users to explore the website's functionalities without performing real-time queries. On the index page, a dedicated section provides an example tracking ID, which users can copy and paste into the history track page to retrieve precomputed results. Alternatively, users can enter the tracking ID directly into the analysis pages to load the corresponding data without waiting for new computations. Since all results are already stored in the database, they are retrieved instantly.</p>
        </div>
        <div class="experience" id="experience">
            <h2>User Experience</h2>
            <p>On the index page, the top navigation bar allows users to jump directly to the analysis section and choose a specific analysis type. It also provides quick access to the search and history sections. The footer navigation on the index page enables direct navigation to the Help and About pages. On all other pages, a HOME button is available in the bottom right corner, allowing users to return to the index page effortlessly. After completing an analysis, users can conveniently click the return button to navigate back to the analysis selection page. The history page also enhances the user experience by detecting when a user has only completed a sequence search without performing an analysis. In such cases, the interface encourages the user to proceed directly to an analysis page, streamlining the workflow.</p>
            <p>Both the About and Help pages feature a floor-based navigation system, allowing users to quickly jump to specific sections by clicking on the sidebar menu. The navigation bar dynamically updates its style based on user interactions, ensuring that the currently selected section is visually highlighted. This functionality is implemented using a combination of click event listeners and scroll event tracking, allowing for a smooth and responsive experience. When a user clicks on a navigation item, the page automatically scrolls to the corresponding section, and the clicked navigation item is visually highlighted. To maintain synchronization between the sidebar and the visible content, the scroll event tracks the user's position on the page. By monitoring window.scrollY in relation to each section's offsetTop value, JavaScript determines which section is currently in view. This ensures that even when scrolling manually, the correct navigation item is dynamically updated and highlighted. This feature significantly enhances usability, particularly on pages with large amounts of content, by minimizing excessive scrolling and providing an intuitive browsing experience.</p>
            <p>In both the search and history pages, if a query returns no results, an error message is displayed. When the user begins typing a new query, the error message automatically disappears, restoring the input field to its original state. For analysis failures, an error notification appears, and the page automatically refreshes to prompt the user to retry. This eliminates the need for manual page refreshes, ensuring users do not get stuck on an error page.</p>
            <p>To improve data visualization, the conservation analysis results include a graphical representation, while the motif analysis summarizes key findings, preventing users from having to manually inspect compressed result files. The tree analysis processes the tree file format to ensure that, when uploaded to iTOL, the nodes display protein names and species names instead of unreadable accession numbers, making the results more intuitive. The history tracking section presents analysis records in a structured table format, making it easier for users to review past results.</p>
            <p>All frontend-backend interactions are handled using the fetch API, providing a smoother and more dynamic user experience. Unlike traditional form submissions that require a full-page refresh, fetch-based interactions allow data to update seamlessly without reloading the page. This enhances responsiveness and ensures a more efficient and user-friendly experience throughout the website.</p>
        </div>
        <div class="credits" id="credits">
            <h2>Statement of Credits</h2>
            <h3 class="more-sugar-font">AI Tools</h3>
            <p>ChatGPT was used to outline the website structure, determine the number of pages, and define their functionalities. It also assisted in debugging code errors, learning PDO for database interactions, refining grammar, logic, and vocabulary in page content, and understanding await/async in JavaScript. Additionally, it was used to learn how to execute Python scripts from PHP, handle parameter passing, retrieve results, and work with PHP arrays.</p>
            <h3 class="more-sugar-font">Code Sources</h3>
            <p>The website integrates animations from Animate.css, sourced from <a target="_blank" href="https://animate.style/#usage">https://animate.style/#usage</a>.</p>
            <p>The website design and layout were created using CANVA, and the following images were obtained from the platform:
                active_box.png, bord_box.png, Figures.png, loading.gif, heart.png, heart_box.png, original_box.png
                [Source: CANVA - <a target="_blank" href="https://www.canva.com/">https://www.canva.com/</a>]
            </p>
            <p>Additional images, including bird.png, background.jpg, pic1, pic2, pic3, were sourced from Pixabay
                [<a target="_blank" href="https://pixabay.com/zh/photos/">https://pixabay.com/zh/photos/</a>].
            </p>
            <p>The image download_box.png was hand-drawn by the author.</p>
            <p>Website favicon icons were sourced from [<a target="_blank" href="https://favicon.io/emoji-favicons/exploding-head/">https://favicon.io/emoji-favicons/exploding-head/</a>].</p>
            <p>The search icon font file was obtained from [<a target="_blank" href="https://www.iconfont.cn/fonts">https://www.iconfont.cn/fonts</a>].</p>
            <p>The custom font files were downloaded from:</p>
            <p>&nbsp;&nbsp;&nbsp;&nbsp;* More Sugar font: <a target="_blank" href="https://www.dafont.com/more-sugar.font">https://www.dafont.com/more-sugar.font</a></p>
            <p>&nbsp;&nbsp;&nbsp;&nbsp;* Gagalin font: <a target="_blank" href="https://font.download/font/gagalin">https://font.download/font/gagalin</a></p>
        </div>
     </section>

     <!-- footer part: return to home page -->
    <a class="return-home sprite-left5 animate__animated animate__slideInUp" href="/~s2647596/index.html"></a>

    <!-- import js file -->
    <script src="./js/about.js" type="module"></script>
</body>
</html>